# -*- coding: utf-8 -*-
"""product_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EA4ySYj7oWV40aRjnf7IqJA_8xyAHZsv
"""

import streamlit as st
import json
import re
import requests
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
from streamlit.components.v1 import html

# --- Your Existing Code ---
HUGGINGFACE_API_URL = "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1"
HEADERS = {"Authorization": "Bearer YOUR API KEY HERE"}

# Load dataset
try:
    data = pd.read_excel("pre_boston(4).xlsx")  # Assuming dataset is in the same folder
except FileNotFoundError:
    st.error("Error: The dataset file was not found. Please ensure 'pre_boston(4).xlsx' is in the same directory as app.py.")
    st.stop()

# Updated Category mappings
category_mapping = {
    "laptops": ["laptop", "macbook"],
    "smartphone": ["smartphone", "phone", "iphone", "galaxy", "mobile", "mobiles", "phones"],
    "basic cases": ["case", "cover"],
    "headphones": ["headphone", "earphone", "earbuds"],
    "laptop bags": ["laptop bag", "backpack"],
    "laptop charger": ["laptop charger", "macbook charger"],
    "phone charger": ["phone charger", "mobile charger"],
    "screen protector": ["screen protector", "tempered glass"],
    "mouse": ["mouse", "wireless mouse"]
}

# Load embedding model
@st.cache_resource
def load_model():
    return SentenceTransformer('all-MiniLM-L6-v2')

model = load_model()

# Generate embeddings
@st.cache_data
def generate_embeddings(df, _model_instance):
    df['text'] = df['product_title'] + " " + df['model'].fillna('') + " " + df['features'].fillna('')
    return _model_instance.encode(df['text'].tolist(), convert_to_numpy=True)

embeddings = generate_embeddings(data, model)

# Create FAISS index
@st.cache_resource
def create_faiss_index(embeddings_array):
    dimension = embeddings_array.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings_array)
    return index

index = create_faiss_index(embeddings)

# Stores previous query context for follow-ups (using Streamlit's session state)
if 'query_memory' not in st.session_state:
    st.session_state['query_memory'] = {}

# Stopwords to remove from queries
stopwords = {"i", "am", "looking", "for", "want", "to", "buy", "need", "a", "an", "the", "of", "with"}
def remove_stopwords(query):
    words = query.lower().split()
    filtered_words = [word for word in words if word not in stopwords]
    return " ".join(filtered_words)

def query_huggingface(payload):
    response = requests.post(HUGGINGFACE_API_URL, headers=HEADERS, json=payload)
    try:
        return response.json()
    except json.JSONDecodeError:
        st.error("Error: Response from Hugging Face is not valid JSON!")
        return None

def extract_query_info(user_query):
    # Apply stopword removal to the user query before passing to the LLM
    processed_query = remove_stopwords(user_query)
    prompt = f"""
    You are an AI assistant that extracts key details from user queries for product recommendations.
    Identify the product category (from: {list(category_mapping.keys())}), brand (if mentioned),
    model (if mentioned), minimum price (if specified), and maximum price (if specified) from the following query.

    Return the output in **valid JSON format** with these keys:
    {{"brand": "...", "model": "...", "category": "...", "min_price": ..., "max_price": ...}}
    If a specific category is not explicitly mentioned, try to infer it based on keywords.
    If price is not mentioned, the value should be null.

    User Query: "{processed_query}"
    JSON Output:
    """
    response = query_huggingface({"inputs": prompt})
    if response is None or not isinstance(response, list) or len(response) == 0:
        print("Error: LLM response is empty or invalid!")
        return {}
    raw_text = response[0].get("generated_text", "").strip()
    try:
        extracted_info = json.loads(raw_text)
        # Post-process category to match the keys in category_mapping
        if "category" in extracted_info and extracted_info["category"]:
            extracted_info["category"] = extracted_info["category"].lower()
            for key, values in category_mapping.items():
                if extracted_info["category"] in values:
                    extracted_info["category"] = key
                    break
            else:
                print(f"Warning: Extracted category '{extracted_info['category']}' not found in mapping.")
                extracted_info.pop("category", None) # Remove if not found
        return extracted_info
    except json.JSONDecodeError:
        # Remove or comment out this line to prevent the error message from being displayed
        # print("Error: Extracted info is not valid JSON!", raw_text)
        return {}

def retrieve_products(query, top_k=50):
    query_embedding = model.encode([query], convert_to_numpy=True)
    D, I = index.search(query_embedding, top_k)
    return data.iloc[I[0]], D[0]

def filter_and_rank_products(user_query, retrieved_products_df, distances, extracted_info):
    brand = extracted_info.get("brand", "").lower()
    model = extracted_info.get("model", "").lower()
    category = extracted_info.get("category", "").lower() if extracted_info.get("category") else None
    min_price = extracted_info.get("min_price")
    max_price = extracted_info.get("max_price")

    exact_brand_model_matches = pd.DataFrame()
    exact_brand_matches = pd.DataFrame()
    other_matches = pd.DataFrame()
    exact_brand_model_indices = []
    exact_brand_indices = []

    if brand:
        brand_match = retrieved_products_df[retrieved_products_df["brand"].str.lower() == brand]
        if not brand_match.empty and model:
            exact_brand_model_matches = brand_match[brand_match["model"].str.lower() == model]
            if not exact_brand_model_matches.empty:
                exact_brand_model_indices.extend(exact_brand_model_matches.index)
        elif not brand_match.empty:
            exact_brand_matches = brand_match[~brand_match["model"].str.lower().str.contains(model, na=False)]
            exact_brand_indices.extend(exact_brand_matches.index)

    remaining_matches = retrieved_products_df[~retrieved_products_df.index.isin(exact_brand_model_indices + exact_brand_indices)]

    if category:
        exact_brand_model_matches = exact_brand_model_matches[
            exact_brand_model_matches["category"].str.lower().str.contains(category, case=False, na=False)
        ]
        exact_brand_matches = exact_brand_matches[
            exact_brand_matches["category"].str.lower().str.contains(category, case=False, na=False)
        ]
        remaining_matches = remaining_matches[
            remaining_matches["category"].str.lower().str.contains(category, case=False, na=False)
        ]

    def filter_by_price(df, min_p, max_p):
        filtered_df = df.copy()
        if min_p is not None and max_p is not None:
            filtered_df = filtered_df[(filtered_df["price"] >= min_p) & (filtered_df["price"] <= max_p)]
        elif max_p is not None:
            filtered_df = filtered_df[filtered_df["price"] <= max_p]
        elif min_p is not None:
            filtered_df = filtered_df[filtered_df["price"] >= min_p]
        return filtered_df

    exact_brand_model_matches = filter_by_price(exact_brand_model_matches, min_price, max_price)
    exact_brand_matches = filter_by_price(exact_brand_matches, min_price, max_price)
    remaining_matches = filter_by_price(remaining_matches, min_price, max_price)

    ranked_exact_brand_model = exact_brand_model_matches.sort_values(by=["review_count", "rating"], ascending=[False, False]) if not exact_brand_model_matches.empty else pd.DataFrame()
    ranked_exact_brand = exact_brand_matches.sort_values(by=["review_count", "rating"], ascending=[False, False]) if not exact_brand_matches.empty else pd.DataFrame()

    if not remaining_matches.empty:
        remaining_match_distances_indices = [i for idx, i in enumerate(retrieved_products_df.index) if i in remaining_matches.index]
        remaining_match_distances = distances[retrieved_products_df.index.isin(remaining_matches.index)]
        if len(remaining_match_distances) == len(remaining_matches):
            remaining_matches['distance'] = remaining_match_distances
            ranked_remaining = remaining_matches.sort_values(by=['distance', "review_count", "rating"], ascending=[True, False, False])
            remaining_matches.drop(columns=['distance'], inplace=True)
        else:
            ranked_remaining = remaining_matches.sort_values(by=["review_count", "rating"], ascending=[False, False])
    else:
        ranked_remaining = pd.DataFrame()

    final_results = pd.concat([ranked_exact_brand_model, ranked_exact_brand, ranked_remaining]).head(10)
    return final_results

def generate_response(user_query):
    processed_query = remove_stopwords(user_query)
    retrieved_products, distances = retrieve_products(processed_query, top_k=50)
    if retrieved_products.empty:
        st.session_state['query_memory'] = {}
        return {"response": "No relevant products found.", "recommended_products": []}

    extracted_info = extract_query_info(user_query)
    filtered_products = filter_and_rank_products(user_query, retrieved_products, distances, extracted_info)

    if filtered_products.empty:
        st.session_state['query_memory'] = {}
        return {"response": "No products found after filtering.", "recommended_products": []}

    st.session_state['query_memory'] = {
        "category": extracted_info.get("category"),
        "brand": extracted_info.get("brand"),
        "model": extracted_info.get("model"),
        "min_price": extracted_info.get("min_price"),
        "max_price": extracted_info.get("max_price"),
        "retrieved_products": filtered_products[:10].to_dict(orient="records") # Store as dictionaries
    }

    return {
        "query": user_query,
        "recommended_products": filtered_products[:10].to_dict(orient="records"),
        "response": "Top results based on your query."
    }

def handle_follow_up(follow_up_query):
    if not st.session_state['query_memory']:
        return {"response": "No previous query found.", "recommended_products": []}

    products_df = pd.DataFrame(st.session_state['query_memory']['retrieved_products'])
    if products_df.empty:
        return {"response": "No products from the previous query.", "recommended_products": []}

    processed_follow_up = remove_stopwords(follow_up_query)
    if "cheaper" in processed_follow_up:
        products = products_df.sort_values(by="price", ascending=True).to_dict(orient="records")
    elif "expensive" in processed_follow_up:
        products = products_df.sort_values(by="price", ascending=False).to_dict(orient="records")
    else:
        return {"response": "Sorry, I can only handle 'cheaper' or 'expensive' follow-up queries right now.", "recommended_products": []}

    return {
        "query": follow_up_query,
        "recommended_products": products[:10],
        "response": "Follow-up recommendations."
    }

# --- Streamlit Interface ---
st.title("Product Recommendation Chatbot")
user_query = st.text_input("Enter your query:", "")

if user_query:
    if any(keyword in remove_stopwords(user_query) for keyword in ["cheaper", "expensive"]):
        response = handle_follow_up(user_query)
    else:
        response = generate_response(user_query)

    st.subheader(response.get("response", "Response:"))
    recommended_products = response.get("recommended_products", [])
    if recommended_products:
        for index, product in enumerate(recommended_products):
            col_left, col_middle, col_right = st.columns([0.3, 0.5, 0.2])

            with col_left:
                if 'image_url' in product and product['image_url']:
                    st.image(product['image_url'], width=150)

            with col_middle:
                st.markdown(f"**{product['product_title']}**")
                st.markdown(f"<small>Product ID: {product['product_id']}</small>", unsafe_allow_html=True)
                st.markdown(f"Rating: {product['rating']} ‚≠ê")
                st.markdown(f"({product['review_count']} Reviews)")
                st.markdown(f"Brand: {product['brand']}")
                st.markdown(f"Model: {product['model']}")
                st.markdown(f"Price: ‚Çπ{product['price']:,}")

                product_details = product.get('text', product.get('features', 'No details available'))
                if product_details != 'No details available':
                    with st.expander(f"Product Details for {product['product_id']}"): # Make expander key unique too
                        st.markdown(f"**Product Information:**\n\n{product_details}")

            with col_right:
                if st.button("üõí Add to Cart", key=f"add_cart_{product['product_id']}_{index}"):
                    st.success(f"Added '{product['product_title']}' to cart!")
                if st.button("üöÄ Buy Now", key=f"buy_now_{product['product_id']}_{index}"):
                    st.info(f"Redirecting to purchase page for '{product['product_title']}'...")

            st.markdown("---")

    elif "error" in response.get("response", "").lower():
        st.error(response["response"])
    elif "warning" in response.get("response", "").lower():
        st.warning(response["response"])
    elif "no products" in response.get("response", "").lower():
        st.info(response["response"])

